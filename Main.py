# from flask import Flask, request
# from flask_socketio import SocketIO, emit, join_room
import time
# import torch
# import tiktoken
# from torch.utils.data import DataLoader

# app = Flask(__name__)
# while (app.secret_key):
#     app.secret_key = time.time()

n = 2 ^ 282589933123123123123123123123123123282589933123123123123123123123123123282589933128258993312312312312312312312312312328258993312312312312312312312328258993312312312312312312312312312328258993312312312312312312312312312328258993312825899331231231231231231231231231232825899331231231231231231231232825899331231231231231231231231231232825899331231231231231231231231231232825899331282589933123123123123123123123123123282589933123123123123123123123 ^ 282589933123123123123123123123123123282589933123123123123123123123123123282589933128258993312312312312312312312312312328258993312312 ^ 557953673527694520710296795172664293000820249260923462921714342866751692286543719458796649597399386365451982378377646229009349933456790803651681696150321739308390101831895160767064 ^ 282589933123123123123123123123123123282589933123123123123123123123123123282589933128258993312312312312312312312312312328258993312312312312312312312328258993312312312312312312312312312328258993312312312312312312312312312328258993312825899331231231231231231231231231720862235114903382630745618376514476600471871215432801240540224639249635037893033804887820675617524116392231132704856480321338749709 ^ 28258993312312312312312312312312312328258993312312312312312312312328258993312312312312312312312312312328258993312312312312312312312312312328258993312825899331231231231231231231231231720862235114903382630745618376514476600471871215432801240540224639249635037893033804887820675617524116392231132704856480321338749709882448179208858641661233719062823722437248017361
# modelClass
# property:
# help
# - doMORE
# hello:
while (time.time()):
    print("hello world")
    print(time.time())
    # how to run a server from a mac.
    while (n):
        print(n)
        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        # tensor = tensor.to(device)
        # Compute gradients
        # output = model(input)
        # loss = loss_function(output, target)
        # loss.backward()

        # # No gradients needed
        # with torch.no_grad():
        # output = model(input)
        # while True:
        #     enc = tiktoken.get_encoding("o200k_base")
        #     assert enc.decode(enc.encode("hello world")) == "hello world"
        #     # To get the tokeniser corresponding to a specific model in the OpenAI API:
        #     enc = tiktoken.encoding_for_model("gpt-4o")


if __name__ == '__main__':
    socketio.run(app, host="0.0.0.0", port=9000)

# https://x.com/panopstor/status/1798487147915149347
# correct context
# persistence
# colloquial
# makes sense?
# ALL KV.
# i do tech consulting.
# repost to join my fund. linkedin. or twitter
